# Interactive Wiki + Chatbot Setup Guide

Complete setup for the Wikipedia-style summary with embedded RAG chatbot.

---

## üöÄ Backend Setup (Complete)

All backend components are ready to use!

### Files Created:

1. **generate_wiki.py** - Generates Wikipedia-style summary
2. **chatbot.py** - RAG chatbot with semantic search
3. **app.py** - Updated with 2 new endpoints

### API Endpoints:

#### POST /api/wiki/generate
Generates Wikipedia-style markdown summary from your knowledge graph.

**Request:**
```bash
curl -X POST http://localhost:5000/api/wiki/generate
```

**Response:**
```json
{
  "content": "# Project Alpha\n\n## Overview...",
  "length": 3451,
  "status": "success"
}
```

#### POST /api/wiki/chat
Ask questions about documents with RAG (Retrieval-Augmented Generation).

**Request:**
```bash
curl -X POST http://localhost:5000/api/wiki/chat \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What database was chosen?",
    "chat_history": []
  }'
```

**Response:**
```json
{
  "answer": "Initially, MongoDB was chosen...",
  "sources": [
    {
      "doc_id": "doc_1",
      "title": "Project Alpha - Kickoff",
      "date": "2024-01-15",
      "similarity": 0.85
    }
  ]
}
```

---

## üíª Frontend Integration

### Option 1: Add to Existing App

1. **Install react-markdown** (if not installed):
```bash
cd client
npm install react-markdown
```

2. **Copy the component files:**
   - `WikiPage.jsx` ‚Üí Already in `client/src/`
   - `WikiPage.css` ‚Üí Already in `client/src/`

3. **Add to your router** (e.g., App.jsx):
```javascript
import WikiPage from './WikiPage';

// In your router:
<Route path="/wiki" element={<WikiPage />} />
```

4. **Add navigation link**:
```javascript
<Link to="/wiki">üìñ Knowledge Wiki</Link>
```

### Option 2: Test Standalone

```bash
cd client
npm install react-markdown
npm start

# Then navigate to http://localhost:3000/wiki
```

---

## üß™ Testing

### Test Backend Endpoints

**1. Generate Wiki:**
```bash
# Generate wiki content
curl -X POST http://localhost:5000/api/wiki/generate | python -m json.tool

# Check saved file
cat backend/wiki.md
```

**2. Test Chatbot:**
```bash
# Ask a question
curl -X POST http://localhost:5000/api/wiki/chat \
  -H "Content-Type: application/json" \
  -d '{"question": "What contradictions exist in the documents?"}' \
  | python -m json.tool
```

**3. Test with conversation history:**
```bash
curl -X POST http://localhost:5000/api/wiki/chat \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What happened after that?",
    "chat_history": [
      {"role": "user", "content": "What database was chosen?"},
      {"role": "assistant", "content": "MongoDB was initially chosen..."}
    ]
  }' | python -m json.tool
```

### Test Frontend

1. **Start the backend:**
```bash
cd backend
python app.py
```

2. **Start the frontend:**
```bash
cd client
npm start
```

3. **Navigate to wiki page:**
   - Go to `http://localhost:3000/wiki`
   - Wiki should load automatically
   - Click chat button in bottom-right
   - Try asking: "What database was chosen?"

---

## üìã Features

### Wiki Page:
- ‚úÖ Auto-generated Wikipedia-style summary
- ‚úÖ Clean markdown formatting
- ‚úÖ Sections: Overview, Timeline, Contradictions, etc.
- ‚úÖ Based on your actual documents

### Chatbot:
- ‚úÖ Floating button in bottom-right corner
- ‚úÖ Opens as overlay panel (doesn't disturb wiki)
- ‚úÖ Semantic search finds relevant docs
- ‚úÖ RAG-powered answers with sources
- ‚úÖ Conversation history support
- ‚úÖ Suggested questions for quick start
- ‚úÖ Typing indicator while thinking

---

## üéØ Demo Flow for Judges

**1. Show the Graph ‚Üí Wiki ‚Üí Chat progression:**

```
"First, we processed the documents..."
[Show graph visualization]

"Then we generated this Wikipedia-style summary..."
[Navigate to /wiki]

"And you can ask questions about any of it!"
[Click chat button, ask "What contradictions exist?"]
```

**2. Highlight the Magic:**
- "The wiki is auto-generated by AI analyzing the knowledge graph"
- "The chatbot uses semantic search to find relevant docs"
- "It preserves sources so you can verify answers"
- "Notice it found the MongoDB ‚Üí PostgreSQL conflict automatically"

**3. Show Follow-up Questions:**
```
Q: "What database was chosen?"
A: "MongoDB was initially chosen..."

Q: "Why did they change?"
A: "They encountered performance issues..." [Shows it has conversation context]
```

---

## üîß Customization

### Change Wiki Prompt

Edit `generate_wiki.py` line ~25 to modify the prompt:
```python
prompt = f"""You are writing a Wikipedia-style article...
[Your custom instructions here]
```

### Adjust Search Parameters

Edit `chatbot.py` line ~33:
```python
# Change number of documents to search
relevant = semantic_search(question, documents, top_k=3)  # Change 3 to 5
```

### Modify Chat UI

Edit `WikiPage.css` to change colors, size, position:
```css
.chat-panel {
  width: 400px;  /* Make wider: 500px */
  height: 600px; /* Make taller: 700px */
}
```

---

## üêõ Troubleshooting

**Wiki not generating?**
```bash
# Make sure backend is running
cd backend
python app.py

# Check if graph.json and documents.json exist
ls -lh graph.json documents.json

# Try manual generation
python generate_wiki.py
```

**Chatbot not responding?**
```bash
# Test the chatbot directly
python chatbot.py

# Check if embedding model loaded
# Should see: "[OK] Chatbot ready"
```

**CORS errors in browser?**
- Flask-CORS is enabled in app.py
- Make sure backend is on port 5000
- Check browser console for specific error

**"ModuleNotFoundError"?**
```bash
# Install missing packages
pip install sentence-transformers google-generativeai python-dotenv flask flask-cors
```

---

## üìä Performance Tips

**For faster responses:**

1. **Reduce top_k** (fewer documents searched):
```python
# chatbot.py line 33
relevant = semantic_search(question, documents, top_k=2)  # Instead of 3
```

2. **Cache the embedding model** (already done):
```python
# Model is loaded once at module level
embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
```

3. **Limit chat history** (already done):
```python
# chatbot.py line 58
for msg in chat_history[-3:]:  # Only last 3 messages
```

---

## üé® UI Features

**Built-in:**
- Responsive design (mobile-friendly)
- Smooth animations
- Typing indicators
- Suggested questions
- Source citations
- Conversation history
- Auto-scroll

**Chat positioning:**
- Bottom-right corner (default)
- Can be moved in CSS

---

## üìù Example Questions to Demo

**For judges:**
1. "What database was chosen for the project?"
2. "What contradictions exist in the documents?"
3. "Tell me about the budget changes"
4. "What security requirements were added?"
5. "Who are the team members?"

**Follow-up questions:**
1. "Why did they change it?"
2. "When did this happen?"
3. "What was the impact?"

---

## ‚úÖ Checklist Before Demo

- [ ] Backend running (`python app.py`)
- [ ] graph.json and documents.json exist
- [ ] Wiki generated (`python generate_wiki.py`)
- [ ] Frontend running (`npm start` in client/)
- [ ] Test wiki page loads
- [ ] Test chat button appears
- [ ] Test asking a question
- [ ] Test sources appear
- [ ] GEMINI_API_KEY in .env file

---

## üéì Technical Details

**RAG Architecture:**
```
Question ‚Üí Embedding ‚Üí Cosine Similarity ‚Üí Top-3 Docs ‚Üí Gemini API ‚Üí Answer
```

**Why it works:**
1. **Semantic Search**: Finds relevant docs even with different wording
2. **Context Window**: Provides actual doc content to LLM
3. **Source Tracking**: Returns which docs were used
4. **Conversation Memory**: Keeps last 3 messages for context

**Token Efficiency:**
- Only sends top-3 most relevant docs (not all docs)
- Limits chat history to last 3 turns
- Uses fast Gemini 2.0 Flash model

---

**Ready to wow the judges! üöÄ**
